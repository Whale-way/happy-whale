{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eeced39",
   "metadata": {},
   "source": [
    "# Whale and Dolphin Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67eaa49",
   "metadata": {},
   "source": [
    "Authors:\n",
    "- Victor Möslein\n",
    "- Maren Rieker\n",
    "- Reed Garvin\n",
    "- Dinah Rabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4286612",
   "metadata": {},
   "source": [
    "This Notebook is one of three core notebooks of the Whale and Dolphin Classification Project for the \"Machine Learning\" class at the Hertie School of Governance. It focuses on the application of classic machine learning models to the task at hand. There is one other notebook concerned with data preprocessing and another that focuses on the application of a deep learning model. \n",
    "\n",
    "The code of this nootebook partly follows the chapter on Classification from the book \"Hands-on Machine Learning with Scikit-Learn, Keras, and Tensorflow\" by Aurélien Géron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e02e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup: System settings and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2b14a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "from numpy import savez_compressed\n",
    "import os\n",
    "import timeit\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# to make this notebook's output stable\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d038a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7a758",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_switch_on = False # if the full data set should be used, this switch need to be set to true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2904196d",
   "metadata": {},
   "source": [
    "## Define paths to data and for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1605ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ROOT_FIGS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5yt19bqs6bv_03rdznqvkyym0000gn/T/ipykernel_80556/3603191458.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# where to save figures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mROOT_PATH_FIG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"output/ml_models/01_figures\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROOT_FIGS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# where to save output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ROOT_FIGS' is not defined"
     ]
    }
   ],
   "source": [
    "# path to clean data folder\n",
    "ROOT_PATH_DATA = \"input/04_cleaned/\"\n",
    "\n",
    "# where to save figures\n",
    "ROOT_PATH_FIG = \"output/ml_models/01_figures\"\n",
    "os.makedirs(ROOT_FIGS, exist_ok=True)\n",
    "\n",
    "# where to save output\n",
    "\n",
    "ROOT_OUTPUT = \"output/ml_models/\"\n",
    "OUTPUT_PATH_TRAIN_EVAL = os.path.join(ROOT_OUTPUT + \"02_training_set_evaluation\")\n",
    "OUTPUT_PATH_TEST_EVAL = os.path.join(ROOT_OUTPUT + \"03_test_set_evaluation\")\n",
    "OUTPUT_PATH_HYPPAR_TUN = os.path.join(ROOT_OUTPUT + \"04_hyperparamter_tuning\")\n",
    "OUTPUT_PATH_RUN_TIME = os.path.join(ROOT_OUTPUT + \"05_runtime_stats\")\n",
    "\n",
    "# function to save figures\n",
    "\n",
    "def save_fig(fig_id, SAVE_PATH=ROOT__PATH_FIG, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(SAVE_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\">... Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6521a742",
   "metadata": {},
   "source": [
    "## Loading and splitting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf718251",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(ROOT_PATH_DATA + \"train/clean_sample_train.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ff5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_full = labels_df[\"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "52d3f4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_ids_full = labels_df[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "753fd84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npz files ## has to be adjusted to the actual one\n",
    "img_data = np.load(\"input/04_cleaned/train/img_data_sample_224.npz\")\n",
    "img_data_full = img_data[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c5cbefd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/d0/5yt19bqs6bv_03rdznqvkyym0000gn/T/ipykernel_80556/3835493187.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split into training and test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimg_data_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_data_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_ids_train_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_ids_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_data_full\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpic_ids_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2195\u001b[0m                      random_state=random_state)\n\u001b[1;32m   2196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \"\"\"\n\u001b[1;32m   1386\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_indices\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1713\u001b[0m         \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1715\u001b[0;31m             raise ValueError(\"The least populated class in y has only 1\"\n\u001b[0m\u001b[1;32m   1716\u001b[0m                              \u001b[0;34m\" member, which is too few. The minimum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1717\u001b[0m                              \u001b[0;34m\" number of groups for any class cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The least populated class in y has only 1 member, which is too few. The minimum number of groups for any class cannot be less than 2."
     ]
    }
   ],
   "source": [
    "# Split into training and test set - 10.000 test set / 40.000 full training set\n",
    "\n",
    "##Victor: das funktioniert nicht mit unserem Sample Set weil wir da species mit nur 1 haben, \n",
    "## aber stratify = labels sollte es verhältnismäßig zu den species splitten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_data_train_full, img_data_test, labels_train_full, labels_test, pic_ids_train_full, pic_ids_test = train_test_split(img_data_full , labels_full, pic_ids_full, stratify=labels_full, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12ee90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and validation set - 30.000 training set / 10.000 validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_data_train, img_data_val, labels_train, labels_val, pic_ids_train, pic_ids_val = train_test_split(img_data_train_full , labels_train_full, pic_ids_train_full, train_size=30000, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce4f685",
   "metadata": {},
   "source": [
    "## Implementing base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f3bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clasf(classifier_x, img_data_train, labels_train):        \n",
    "    # set name of classifier\n",
    "    classifier_name = classifier_x.__class__.__name__\n",
    "    \n",
    "    # train model\n",
    "    print(\">... Starting training of\", classifier_name)\n",
    "    start_time = timeit.default_timer()\n",
    "    classifier_x.fit(img_data_train, labels_train)\n",
    "    time_elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(\">... Classifier {} sucessfully trained in {} seconds.\".format(classifier_name, round(time_elapsed,3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee007575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_LR = LogisticRegression(random_state=42)\n",
    "train_clasf(classifier_LR, img_data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7aae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "## haben wir da eine Präferenz?\n",
    "\n",
    "#in the multiclass case, the training algorithm uses the one-vs-rest (OvR) \n",
    "#scheme if the ‘multi_class’ option is set to ‘ovr’, \n",
    "#and uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’. \n",
    "#‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.\n",
    "#default is \"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c248b5",
   "metadata": {},
   "source": [
    "## Evaluating base line model (\"compute metrics on train AND dev\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c2394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c2d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions of classifier ## Victor: ich war mir nicht ganz sicher ob das so richtig ist\n",
    "pred_train = classifier_LR.predict(img_data_train)\n",
    "pred_val = classifier_LR.predict(img_data_val)\n",
    "\n",
    "# evaluate classifier and store metrics \n",
    "evaluation_scores = {}\n",
    "    evaluation_scores[\"Precision Score Train\"] = precision_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Precision Score Validation\"] = precision_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_train, pred_train, average=None).round(3) ## ich glaube average NONE ist richtig für multiclass, bitte nochmal checken\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_val, pred_val, average=None).round(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd317542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation scores \n",
    "def store_eval_score(image_df):\n",
    "    savez_compressed(OUTPUT_PATH_TRAIN_EVAL + \"/evaluation_scores\"+str(classifier_name)+\".npz\",image_df)\n",
    "    print(\"file successfully stored in: output/ml_models/02_training_set_evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_eval_score(evaluation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab7334",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiclass Confusion Matrix\n",
    "\n",
    "##Victor: ich weiß nicht ob uns das was bringt, aber es könnte theoretisch zeigen falls es bestimmte classes\n",
    "## gibt die schwieriger zu predicten sind bzw. zu mehr Fehlern führen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff407b",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(labels_val,pred_val,labels=labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62064ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the errors \n",
    "output_dict = {}\n",
    "output_array = np.c_[pic_ids_val, labels_val, pred_val] ## adjust name of pic_ids and labels depending on train or val\n",
    "    \n",
    "# Create error array with specific error\n",
    "err_type_arr = np.array([])\n",
    "for i in range(len(output_array)):\n",
    "     if output_array[i,1] != output_array[i,2]:\n",
    "        err_type_arr = np.append(err_type_arr, \"error\")\n",
    "    else:\n",
    "        err_type_arr = np.append(err_type_arr, \"No error\")\n",
    "\n",
    "error_table_pd = pd.DataFrame(output_array)\n",
    "error_table_pd.rename(columns = {0:'Picture ID', 1:\"Label\", 2:\"Predicted\"}, inplace = True)\n",
    "error_table_pd[\"Error Check\"] = err_type_arr\n",
    "\n",
    "# print filtered error table\n",
    "print(error_table_pd.loc[error_table_pd[\"Error Check\"].isin(\"error\")].sort_values(by=[\"Label\", \"Picture ID\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89da3848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function for saving the filtered error table\n",
    "\n",
    "def store_error_table(image_df):\n",
    "    savez_compressed(OUTPUT_PATH_TRAIN_EVAL + \"/error_table\"+str(classifier_name)+\".npz\",image_df)\n",
    "    print(\"file successfully stored in: output/ml_models/02_training_set_evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54b781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform pd frame into dictionary for saving\n",
    "output_dict[\"error_table\"] = error_table_pd\n",
    "\n",
    "# saving the error table\n",
    "store_error_table(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d0da3e",
   "metadata": {},
   "source": [
    "## Implementing RandomForest Classifier as advanced model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fa7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#### Victor: setzen wir direkt eine max_depth= und n_estimators=500 ? \n",
    "## es gibt so viele hyperparameter für RF, bspw auch class_weight - da wusste ich auch nicht genau ob wir das nutzen?\n",
    "## oder ob wir generell all diese variablen erst beim hyperparameter tuning anschauen\n",
    "\n",
    "classifier_RF = RandomForestClassifier(max_depth= ,n_jobs=-1,random_state=42) \n",
    "train_clasf(classifier_RF, img_data_train, labels_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd2e01",
   "metadata": {},
   "source": [
    "## Evaluating RandomForest Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff699a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions of classifier ## Victor: ich war mir nicht ganz sicher ob das so richtig ist\n",
    "pred_train = classifier_RF.predict(img_data_train)\n",
    "pred_val = classifier_RF.predict(img_data_val)\n",
    "\n",
    "# evaluate classifier and store metrics \n",
    "evaluation_scores = {}\n",
    "    evaluation_scores[\"Precision Score Train\"] = precision_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Precision Score Validation\"] = precision_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_train, pred_train, average=None).round(3) ## ich glaube average NONE ist richtig für multiclass, bitte nochmal checken\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_val, pred_val, average=None).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec08c595",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_eval_score(evaluation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02eb7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multiclass Confusion Matrix\n",
    "\n",
    "##Victor: ich weiß nicht ob uns das was bringt, aber es könnte theoretisch zeigen falls es bestimmte classes\n",
    "## gibt die schwieriger zu predicten sind bzw. zu mehr Fehlern führen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf8274",
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_confusion_matrix(labels_val,pred_val,labels=labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e58b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## victor - ich weiß nicht ob wir das machen können, aber vielleicht kannst du es versuchen\n",
    "## https://github.com/harsh1kumar/learning/blob/master/machine_learning/santander_trxn_prediction/02_trxn_pred_rf_basics.ipynb\n",
    "## in dem Notebook unter Step 5 visualisiert der die ROC-AUC für die einzelnen Trees \n",
    "## um die model performance in bezug auf die Anzahl der Trees zu zeigen - find ich ganz cool\n",
    "## bin mir nicht ganz sicher, ob das mit multi-class auch funktioniert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0ed3ac",
   "metadata": {},
   "source": [
    "## Hyperparamter Tuning RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80f90b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83916f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting Parameters of Random Forest Classifier for Grid Search\n",
    "\n",
    "## hey victor hier war ich mir nicht so sicher was wir alles auswählen sollen \n",
    "## ich hab jetzt mal die genommen von denen ich gelesen habe, dass sie wichtig sind\n",
    "# hab den artikel gelesen: https://towardsdatascience.com/random-forest-hyperparameters-and-how-to-fine-tune-them-17aee785ee0d\n",
    "\n",
    "## bei max_features war ich mir aber nicht sicher auf was wir beschränken sollen - es gäbe auch noch \"sqrt\" (None nimmt alle)\n",
    "\n",
    "params_grid_RF = [\n",
    "    {\"n_estimators\": [10, 100, 250],\n",
    "     \"criterion_list\":[\"gini\",\"entropy\"]\n",
    "     \"max_features\": [\"auto\", \"log2\", None],\n",
    "     \"bootstrap\": [True, False]}    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92ee0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Victor: hier müssen wir wieder die max depth fixen\n",
    "\n",
    "classifier_RF_hyper = RandomForestClassifier(max_depth= ,n_jobs=-1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7236087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Grid-Search\n",
    "\n",
    "## Victor: hier war ich mir unsicher bzgl scoring und refit - bitte checken\n",
    "\n",
    "grid_search = GridSearchCV(estimator = classifier_RF_hyper, \n",
    "                           param_grid = params_grid_RF, \n",
    "                           cv=3,\n",
    "                           scoring=[\"precision\", \"recall\", \"accuracy\"],\n",
    "                           refit = \"precision\",\n",
    "                           n_jobs = 4,\n",
    "                           verbose = 3,\n",
    "                           return_train_score = True)\n",
    "    \n",
    "grid_search.fit(img_data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab0bd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search.best_params_)\n",
    "best_hyppar_dict = {}\n",
    "best_hyppar_dict[\"Grid_Search_Best_Params\"] = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9fa866",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_best_hyperpar(image_df):\n",
    "    savez_compressed(OUTPUT_PATH_HYPPAR_TUN + \"/best_hyperpar\"+str(classifier_name)+\".npz\",image_df)\n",
    "    print(\"file successfully stored in: output/ml_models/04_hyperparamter_tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_best_hyperpar(best_params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0f726",
   "metadata": {},
   "source": [
    "## Evaluate tuned classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ac40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define the tuned classifier with the best hyperparamters ## these here are still random ones\n",
    "\n",
    "classifier_RF_tuned = RandomForestClassifier(class_weight='balanced',\n",
    "                                      criterion='gini',\n",
    "                                      max_depth=55,\n",
    "                                      max_features='log2',\n",
    "                                      min_samples_leaf=0.005,\n",
    "                                      min_samples_split=0.005,\n",
    "                                      n_estimators=190)\n",
    "\n",
    "classifier_RF_tuned.fit(image_data_train,labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce6b15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions of classifier ## Victor: ich war mir nicht ganz sicher ob das so richtig ist\n",
    "pred_train = classifier_RF_tuned.predict(img_data_train)\n",
    "pred_val = classifier_RF_tuned.predict(img_data_val)\n",
    "\n",
    "# evaluate classifier and store metrics \n",
    "evaluation_scores = {}\n",
    "    evaluation_scores[\"Precision Score Train\"] = precision_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Precision Score Validation\"] = precision_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_train, pred_train).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels_val, pred_val).round(3)\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_train, pred_train, average=None).round(3) ## ich glaube average NONE ist richtig für multiclass, bitte nochmal checken\n",
    "    evaluation_scores[\"F1 Score\"] = f1_score(labels_val, pred_val, average=None).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335a323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_eval_score(evaluation_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57067b2",
   "metadata": {},
   "source": [
    "## Speed improvements through dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b19a13",
   "metadata": {},
   "source": [
    "### Checking Feature importance of RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f572f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the function to plot the digits of feature importance\n",
    "# Adapted from Aurelien Geron:\n",
    "\n",
    "pix_res = 224\n",
    "\n",
    "def plot_digit(data):\n",
    "    image = data.reshape(pix_res, pix_res)\n",
    "    plt.imshow(image, cmap = mpl.cm.hot,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e24b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding feature importances from 3 RGB values to one pixel\n",
    "feature_imp_sum = np.empty([(int(len(classifier_RF_tuned.feature_importances_)/3)),])\n",
    "\n",
    "for itr in range(int(len(classifier_RF_tuned.feature_importances_)/3)):\n",
    "    r = int(itr*3)\n",
    "    g = int(r+1)\n",
    "    b = int(g+1)\n",
    "    feature_imp_sum[itr] = classifier_RF_tuned.feature_importances_[r] + classifier_RF_tuned.feature_importances_[g] + classifier_RF_tuned.feature_importances_[b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ddb47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting feature importance sum for every pixel to a plot and save it\n",
    "plot_digit(feature_imp_sum)\n",
    "\n",
    "cbar = plt.colorbar(ticks=[feature_imp_sum.min(), feature_imp_sum.max()])\n",
    "cbar.ax.set_yticklabels(['Not important', 'Very important'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0144bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig(\"RandomForest_feature_importance_plot_full_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47542f97",
   "metadata": {},
   "source": [
    "### Performing Principal Component Analysis on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc6735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b638d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1070ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining to keep 99% of the variance of the data \n",
    "pca = PCA(.99)\n",
    "img_data_full_red = pca.fit_transform(img_data_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7987268c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking how many features are left \n",
    "img_data_full_red.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58846e25",
   "metadata": {},
   "source": [
    "### Evaluate speed tuned RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969724ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Victor: muss man dann hier nochmal das ganze training (direkt mit den gefundenen hyperparametern) und \n",
    "# evaluation nochmal machen? Schon oder?\n",
    "# und dann besteht die Gefahr, dass die Hyperparameter nicht mehr ideal sind und man die dann nochmal\n",
    "# fine tunen muss (so wars bei Thilo) aber falls die predictions nicht zu schlecht sind können wir auch argumentieren\n",
    "# dass wir das aufgrund von run-time and scope limitations of our project nicht mehr machen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7435afeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc203db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d44a0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56314899",
   "metadata": {},
   "source": [
    "## Final Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94bcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test baseline and untuned RF on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d07d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## test tuned RD on test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
