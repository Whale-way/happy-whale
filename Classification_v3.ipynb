{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ad1c96",
   "metadata": {},
   "source": [
    "# Whale and Dolphin Classification Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15e938",
   "metadata": {},
   "source": [
    "Authors:\n",
    "- Victor Möslein\n",
    "- Maren Rieker\n",
    "- Reed Garvin\n",
    "- Dinah Rabe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ce653",
   "metadata": {},
   "source": [
    "This Notebook is one of three core notebooks of the Whale and Dolphin Classification Project for the \"Machine Learning\" class at the Hertie School of Governance. It focuses on the application of classic machine learning models to the task at hand. There is one other notebook concerned with data preprocessing and another that focuses on the application of a deep learning model. \n",
    "\n",
    "The code of this nootebook partly follows the chapter on Classification from the book \"Hands-on Machine Learning with Scikit-Learn, Keras, and Tensorflow\" by Aurélien Géron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cac158",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup: System settings and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from numpy import load\n",
    "import pandas as pd\n",
    "from numpy import savez_compressed\n",
    "import os\n",
    "import timeit\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import PIL\n",
    "\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# to make this notebook's output stable\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c11ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb879028",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_switch_on = False # if the full data set should be used, this switch need to be set to true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f950b9e",
   "metadata": {},
   "source": [
    "## Define paths to data and for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to clean data folder\n",
    "ROOT_PATH_DATA = \"input/04_cleaned/\"\n",
    "\n",
    "# where to save figures\n",
    "ROOT_PATH_FIG = \"output/ml_models/01_figures\"\n",
    "os.makedirs(ROOT_FIGS, exist_ok=True)\n",
    "\n",
    "# where to save output\n",
    "\n",
    "ROOT_OUTPUT = \"output/ml_models/\"\n",
    "OUTPUT_PATH_TRAIN_EVAL = os.path.join(ROOT_OUTPUT + \"02_training_set_evaluation\")\n",
    "OUTPUT_PATH_TEST_EVAL = os.path.join(ROOT_OUTPUT + \"03_test_set_evaluation\")\n",
    "OUTPUT_PATH_HYPPAR_TUN = os.path.join(ROOT_OUTPUT + \"04_hyperparamter_tuning\")\n",
    "OUTPUT_PATH_RUN_TIME = os.path.join(ROOT_OUTPUT + \"05_runtime_stats\")\n",
    "\n",
    "# function to save figures\n",
    "\n",
    "def save_fig(fig_id, SAVE_PATH=ROOT_FIG, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(SAVE_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\">... Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286631b6",
   "metadata": {},
   "source": [
    "## Loading and splitting training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e5f30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load npz files\n",
    "img_data_train_full \n",
    "img_data_test\n",
    "# load csv files and subset relevant column\n",
    "labels_train_full\n",
    "labels_test\n",
    "pic_ids_train_full\n",
    "pic_ids_test\n",
    "\n",
    "# Split into training and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "img_data_train, img_data_val, labels_train, labels_val, pic_ids_train, pic_ids_val = train_test_split(img_data_train_full , labels_train_full, pic_ids_train_full, train_size=0.10, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010a9403",
   "metadata": {},
   "source": [
    "## Implementing base line model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e636f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_clasf(classifier_x, img_data_train, labels_train):        \n",
    "    # set name of classifier\n",
    "    classifier_name = classifier_x.__class__.__name__\n",
    "    \n",
    "    # train model\n",
    "    print(\">... Starting training of\", classifier_name)\n",
    "    start_time = timeit.default_timer()\n",
    "    classifier_x.fit(img_data_train, labels_train)\n",
    "    time_elapsed = timeit.default_timer() - start_time\n",
    "    \n",
    "    print(\">... Classifier {} sucessfully trained in {} seconds.\".format(classifier_name, round(time_elapsed,3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e212549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "classifier_LR = LogisticRegression(random_state=42)\n",
    "train_clasf(classifier_LR, img_data_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064ca468",
   "metadata": {},
   "outputs": [],
   "source": [
    "## haben wir da eine Präferenz?\n",
    "\n",
    "#in the multiclass case, the training algorithm uses the one-vs-rest (OvR) \n",
    "#scheme if the ‘multi_class’ option is set to ‘ovr’, \n",
    "#and uses the cross-entropy loss if the ‘multi_class’ option is set to ‘multinomial’. \n",
    "#‘auto’ selects ‘ovr’ if the data is binary, or if solver=’liblinear’, and otherwise selects ‘multinomial’.\n",
    "#default is \"auto\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76750639",
   "metadata": {},
   "source": [
    "## Evaluating base line model (\"compute metrics on train AND dev\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d217edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7625359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store predictions of classifier\n",
    "pred =\n",
    "\n",
    "# evaluate classifier and store metrics ## adjust name of the labels depending on train or val\n",
    "evaluation_scores = {}\n",
    "    evaluation_scores[\"Precision Score\"] = precision_score(labels, pred).round(3)\n",
    "    evaluation_scores[\"Recall Score\"] = recall_score(labels, pred).round(3)\n",
    "    evaluation_scores[\"F1 Score\"] = confusion_matrix(labels, pred).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423501c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation scores \n",
    "def store_eval_score(image_df):\n",
    "    savez_compressed(OUTPUT_PATH_TRAIN_EVAL + \"/evaluation_scores\"+str(classifier_name)+\".npz\",image_df)\n",
    "    print(\"file successfully stored in: output/ml_models/02_training_set_evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8eaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_eval_score(evaluation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a12ae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspecting the errors \n",
    "output_dict = {}\n",
    "output_array = np.c_[pic_ids, labels, pred] ## adjust name of pic_ids and labels depending on train or val\n",
    "    \n",
    "# Create error array with specific error\n",
    "err_type_arr = np.array([])\n",
    "for i in range(len(output_array)):\n",
    "     if output_array[i,1] != output_array[i,2]:\n",
    "        err_type_arr = np.append(err_type_arr, \"error\")\n",
    "    else:\n",
    "        err_type_arr = np.append(err_type_arr, \"No error\")\n",
    "\n",
    "error_table_pd = pd.DataFrame(output_array)\n",
    "error_table_pd.rename(columns = {0:'Picture ID', 1:\"Label\", 2:\"Predicted\"}, inplace = True)\n",
    "error_table_pd[\"Error Check\"] = err_type_arr\n",
    "\n",
    "# print filtered error table\n",
    "print(error_table_pd.loc[error_table_pd[\"Error Check\"].isin(\"error\")].sort_values(by=[\"Label\", \"Picture ID\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa6e69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function for saving the filtered error table\n",
    "\n",
    "def store_error_table(image_df):\n",
    "    savez_compressed(OUTPUT_PATH_TRAIN_EVAL + \"/error_table\"+str(classifier_name)+\".npz\",image_df)\n",
    "    print(\"file successfully stored in: output/ml_models/02_training_set_evaluation\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9af40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform pd frame into dictionary for saving\n",
    "output_dict[\"error_table\"] = error_table_pd\n",
    "\n",
    "# saving the error table\n",
    "store_error_table(output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786ea727",
   "metadata": {},
   "source": [
    "## Implementing RandomForest Classifier as advanced model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
